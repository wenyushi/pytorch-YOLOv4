{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os, sys, math\n",
    "import argparse\n",
    "from collections import deque\n",
    "import datetime\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from dataset import Yolo_dataset\n",
    "from cfg import Cfg\n",
    "from models import Yolov4\n",
    "from tool.darknet2pytorch import Darknet\n",
    "\n",
    "from tool.tv_reference.utils import collate_fn as val_collate\n",
    "from tool.tv_reference.coco_utils import convert_to_coco_api\n",
    "from tool.tv_reference.coco_eval import CocoEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4 Backbone and Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "model = Yolov4(\"./yolov4.conv.137.pth\", n_classes=80)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device=\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model_module = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model_module, \"scripted_yolo_v4.pt\")\n",
    "load_scripted_model = torch.jit.load(\"scripted_yolo_v4.pt\")\n",
    "load_scripted_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b tool/torch_utils.py:57\n",
    "# b models.py:400\n",
    "# b tool/yolo_layer.py:323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerically check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "bboxes_pred = model(torch.zeros(1, 3, 608, 608).to(torch.float32).to(\"cpu\"))\n",
    "bboxes_pred_script = load_scripted_model(torch.zeros(1, 3, 608, 608).to(torch.float32).to(\"cpu\"))\n",
    "np.testing.assert_almost_equal(bboxes_pred[0].detach().numpy(), bboxes_pred_script[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_iou(bboxes_a, bboxes_b, xyxy:bool=True, GIoU:bool=False, DIoU:bool=False, CIoU:bool=False):\n",
    "    \"\"\"Calculate the Intersection of Unions (IoUs) between bounding boxes.\n",
    "    IoU is calculated as a ratio of area of the intersection\n",
    "    and area of the union.\n",
    "\n",
    "    Args:\n",
    "        bbox_a (array): An array whose shape is :math:`(N, 4)`.\n",
    "            :math:`N` is the number of bounding boxes.\n",
    "            The dtype should be :obj:`numpy.float32`.\n",
    "        bbox_b (array): An array similar to :obj:`bbox_a`,\n",
    "            whose shape is :math:`(K, 4)`.\n",
    "            The dtype should be :obj:`numpy.float32`.\n",
    "    Returns:\n",
    "        array:\n",
    "        An array whose shape is :math:`(N, K)`. \\\n",
    "        An element at index :math:`(n, k)` contains IoUs between \\\n",
    "        :math:`n` th bounding box in :obj:`bbox_a` and :math:`k` th bounding \\\n",
    "        box in :obj:`bbox_b`.\n",
    "\n",
    "    from: https://github.com/chainer/chainercv\n",
    "    https://github.com/ultralytics/yolov3/blob/eca5b9c1d36e4f73bf2f94e141d864f1c2739e23/utils/utils.py#L262-L282\n",
    "    \"\"\"\n",
    "    if bboxes_a.shape[1] != 4 or bboxes_b.shape[1] != 4:\n",
    "        raise IndexError\n",
    "\n",
    "    if xyxy:\n",
    "        # intersection top left\n",
    "        tl = torch.max(bboxes_a[:, None, :2], bboxes_b[:, :2])\n",
    "        # intersection bottom right\n",
    "        br = torch.min(bboxes_a[:, None, 2:], bboxes_b[:, 2:])\n",
    "        # convex (smallest enclosing box) top left and bottom right\n",
    "        con_tl = torch.min(bboxes_a[:, None, :2], bboxes_b[:, :2])\n",
    "        con_br = torch.max(bboxes_a[:, None, 2:], bboxes_b[:, 2:])\n",
    "        # centerpoint distance squared\n",
    "        rho2 = ((bboxes_a[:, None, 0] + bboxes_a[:, None, 2]) - (bboxes_b[:, 0] + bboxes_b[:, 2])) ** 2 / 4 + (\n",
    "                (bboxes_a[:, None, 1] + bboxes_a[:, None, 3]) - (bboxes_b[:, 1] + bboxes_b[:, 3])) ** 2 / 4\n",
    "\n",
    "        w1 = bboxes_a[:, 2] - bboxes_a[:, 0]\n",
    "        h1 = bboxes_a[:, 3] - bboxes_a[:, 1]\n",
    "        w2 = bboxes_b[:, 2] - bboxes_b[:, 0]\n",
    "        h2 = bboxes_b[:, 3] - bboxes_b[:, 1]\n",
    "\n",
    "        area_a = torch.prod(bboxes_a[:, 2:] - bboxes_a[:, :2], 1)\n",
    "        area_b = torch.prod(bboxes_b[:, 2:] - bboxes_b[:, :2], 1)\n",
    "    else:\n",
    "        # intersection top left\n",
    "        tl = torch.max((bboxes_a[:, None, :2] - bboxes_a[:, None, 2:] / 2),\n",
    "                       (bboxes_b[:, :2] - bboxes_b[:, 2:] / 2))\n",
    "        # intersection bottom right\n",
    "        br = torch.min((bboxes_a[:, None, :2] + bboxes_a[:, None, 2:] / 2),\n",
    "                       (bboxes_b[:, :2] + bboxes_b[:, 2:] / 2))\n",
    "\n",
    "        # convex (smallest enclosing box) top left and bottom right\n",
    "        con_tl = torch.min((bboxes_a[:, None, :2] - bboxes_a[:, None, 2:] / 2),\n",
    "                           (bboxes_b[:, :2] - bboxes_b[:, 2:] / 2))\n",
    "        con_br = torch.max((bboxes_a[:, None, :2] + bboxes_a[:, None, 2:] / 2),\n",
    "                           (bboxes_b[:, :2] + bboxes_b[:, 2:] / 2))\n",
    "        # centerpoint distance squared\n",
    "        rho2 = ((bboxes_a[:, None, :2] - bboxes_b[:, :2]) ** 2 / 4).sum(dim=-1)\n",
    "\n",
    "        w1 = bboxes_a[:, 2]\n",
    "        h1 = bboxes_a[:, 3]\n",
    "        w2 = bboxes_b[:, 2]\n",
    "        h2 = bboxes_b[:, 3]\n",
    "\n",
    "        area_a = torch.prod(bboxes_a[:, 2:], 1)\n",
    "        area_b = torch.prod(bboxes_b[:, 2:], 1)\n",
    "    en = (tl < br).type(tl.type()).prod(dim=2)\n",
    "    area_i = torch.prod(br - tl, 2) * en  # * ((tl < br).all())\n",
    "    area_u = area_a[:, None] + area_b - area_i\n",
    "    iou = area_i / area_u\n",
    "\n",
    "    if GIoU or DIoU or CIoU:\n",
    "        if GIoU:  # Generalized IoU https://arxiv.org/pdf/1902.09630.pdf\n",
    "            area_c = torch.prod(con_br - con_tl, 2)  # convex area\n",
    "            return iou - (area_c - area_u) / area_c  # GIoU\n",
    "        if DIoU or CIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1\n",
    "            # convex diagonal squared\n",
    "            c2 = torch.pow(con_br - con_tl, 2).sum(dim=2) + 1e-16\n",
    "            if DIoU:\n",
    "                return iou - rho2 / c2  # DIoU\n",
    "            elif CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n",
    "                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w1 / h1).unsqueeze(1) - torch.atan(w2 / h2), 2)\n",
    "#                 with torch.no_grad():\n",
    "                alpha = v / (1 - iou + v)\n",
    "                return iou - (rho2 / c2 + v * alpha)  # CIoU\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class Yolo_loss(nn.Module):\n",
    "#     masked_anchors: List[torch.Tensor]\n",
    "    def __init__(self, n_classes=80, n_anchors=3, device=None, batch: int =2):\n",
    "        super(Yolo_loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.strides = [8, 16, 32]\n",
    "        image_size = 608\n",
    "        self.n_classes = n_classes\n",
    "        self.n_anchors = n_anchors\n",
    "\n",
    "        self.anchors = [[12, 16], [19, 36], [40, 28], [36, 75], [76, 55], [72, 146], [142, 110], [192, 243], [459, 401]]\n",
    "        self.anch_masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "        self.ignore_thre = 0.5\n",
    "\n",
    "        self.masked_anchors, self.ref_anchors, self.grid_x, self.grid_y, self.anchor_w, self.anchor_h = [], [], [], [], [], []\n",
    "\n",
    "        for i in range(3):\n",
    "            all_anchors_grid = [(w / self.strides[i], h / self.strides[i]) for w, h in self.anchors]\n",
    "            masked_anchors = np.array([all_anchors_grid[j] for j in self.anch_masks[i]], dtype=np.float32)\n",
    "            ref_anchors = np.zeros((len(all_anchors_grid), 4), dtype=np.float32)\n",
    "            ref_anchors[:, 2:] = np.array(all_anchors_grid, dtype=np.float32)\n",
    "            ref_anchors = torch.from_numpy(ref_anchors)\n",
    "            # calculate pred - xywh obj cls\n",
    "            fsize = image_size // self.strides[i]\n",
    "            grid_x = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).to(device)\n",
    "            grid_y = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).permute(0, 1, 3, 2).to(device)\n",
    "            anchor_w = torch.from_numpy(masked_anchors[:, 0]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "            anchor_h = torch.from_numpy(masked_anchors[:, 1]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "            masked_anchors = torch.from_numpy(masked_anchors)\n",
    "\n",
    "            self.masked_anchors.append(masked_anchors)\n",
    "            self.ref_anchors.append(ref_anchors)\n",
    "            self.grid_x.append(grid_x)\n",
    "            self.grid_y.append(grid_y)\n",
    "            self.anchor_w.append(anchor_w)\n",
    "            self.anchor_h.append(anchor_h)\n",
    "\n",
    "    def build_target(self, pred, labels, batchsize:int, fsize:int, n_ch:int, output_id:int):\n",
    "        # target assignment\n",
    "        tgt_mask = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 4 + self.n_classes).to(device=self.device)\n",
    "        obj_mask = torch.ones(batchsize, self.n_anchors, fsize, fsize).to(device=self.device)\n",
    "        tgt_scale = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 2).to(self.device)\n",
    "        target = torch.zeros(batchsize, self.n_anchors, fsize, fsize, n_ch).to(self.device)\n",
    "\n",
    "        nlabel = (labels.sum(dim=2) > 0).sum(dim=1)  # number of objects\n",
    "\n",
    "        truth_x_all = (labels[:, :, 2] + labels[:, :, 0]) / (self.strides[output_id] * 2)\n",
    "        truth_y_all = (labels[:, :, 3] + labels[:, :, 1]) / (self.strides[output_id] * 2)\n",
    "        truth_w_all = (labels[:, :, 2] - labels[:, :, 0]) / self.strides[output_id]\n",
    "        truth_h_all = (labels[:, :, 3] - labels[:, :, 1]) / self.strides[output_id]\n",
    "#         truth_i_all = truth_x_all.to(torch.int16).cpu().numpy()\n",
    "#         truth_j_all = truth_y_all.to(torch.int16).cpu().numpy()\n",
    "\n",
    "        for b in range(batchsize):\n",
    "            n = int(nlabel[b])\n",
    "            if n == 0:\n",
    "                continue\n",
    "            truth_box = torch.zeros(n, 4).to(self.device)\n",
    "            truth_box[:n, 2] = truth_w_all[b, :n]\n",
    "            truth_box[:n, 3] = truth_h_all[b, :n]\n",
    "            truth_i = truth_x_all[b, :n]\n",
    "            truth_j = truth_y_all[b, :n]\n",
    "\n",
    "            # calculate iou between truth and reference anchors\n",
    "            anchor_ious_all = bboxes_iou(truth_box.cpu(), self.ref_anchors[output_id], CIoU=True)\n",
    "\n",
    "            # temp = bbox_iou(truth_box.cpu(), self.ref_anchors[output_id])\n",
    "\n",
    "            best_n_all = anchor_ious_all.argmax(dim=1)\n",
    "            best_n = best_n_all % 3\n",
    "            best_n_mask = ((best_n_all == self.anch_masks[output_id][0]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][1]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][2]))\n",
    "\n",
    "            if sum(best_n_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            truth_box[:n, 0] = truth_x_all[b, :n]\n",
    "            truth_box[:n, 1] = truth_y_all[b, :n]\n",
    "\n",
    "            pred_ious = bboxes_iou(pred[b].view(-1, 4), truth_box, xyxy=False)\n",
    "            pred_best_iou, _ = pred_ious.max(dim=1)\n",
    "            pred_best_iou = (pred_best_iou > self.ignore_thre)\n",
    "            pred_best_iou = pred_best_iou.view(pred[b].shape[:3])\n",
    "            # set mask to zero (ignore) if pred matches truth\n",
    "            obj_mask[b] = ~ pred_best_iou\n",
    "\n",
    "            for ti in range(best_n.shape[0]):\n",
    "                if best_n_mask[ti] == 1:\n",
    "                    i, j = truth_i[ti], truth_j[ti]\n",
    "                    a = best_n[ti]\n",
    "                    obj_mask[b, a, j, i] = 1\n",
    "                    tgt_mask[b, a, j, i, :] = 1\n",
    "                    target[b, a, j, i, 0] = truth_x_all[b, ti] - truth_x_all[b, ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 1] = truth_y_all[b, ti] - truth_y_all[b, ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 2] = torch.log(\n",
    "                        truth_w_all[b, ti] / (self.masked_anchors[output_id])[best_n[ti], 0] + 1e-16)\n",
    "                    target[b, a, j, i, 3] = torch.log(\n",
    "                        truth_h_all[b, ti] / (self.masked_anchors[output_id])[best_n[ti], 1] + 1e-16)\n",
    "                    target[b, a, j, i, 4] = 1\n",
    "                    target[b, a, j, i, 5 + labels[b, ti, 4]] = 1\n",
    "                    tgt_scale[b, a, j, i, :] = torch.sqrt(2 - truth_w_all[b, ti] * truth_h_all[b, ti] / fsize / fsize)\n",
    "        return obj_mask, tgt_mask, tgt_scale, target\n",
    "\n",
    "    def forward(self, xin: List[torch.Tensor], labels):\n",
    "        loss = torch.zeros(1).to(device=self.device)\n",
    "        loss_xy= torch.zeros(1).to(device=self.device)\n",
    "        loss_wh:torch.Tensor = torch.zeros(1).to(device=self.device)\n",
    "        loss_obj, loss_cls, loss_l2 = torch.zeros(1).to(device=self.device), torch.zeros(1).to(device=self.device), torch.zeros(1).to(device=self.device)\n",
    "        for output_id, output in enumerate(xin):\n",
    "            batchsize = output.shape[0]\n",
    "            fsize = output.shape[2]\n",
    "            n_ch = 5 + self.n_classes\n",
    "\n",
    "            output = output.view(batchsize, self.n_anchors, n_ch, fsize, fsize)\n",
    "            output = output.permute(0, 1, 3, 4, 2)  # .contiguous()\n",
    "\n",
    "            # logistic activation for xy, obj, cls\n",
    "            applied_sigmoid_idx: List[int] = [0, 1, 4, 5] # torch.cat([torch.arange(2), torch.arange(4, n_ch)])\n",
    "#             output[..., np.r_[:2, 4:n_ch]] = torch.sigmoid(output[..., np.r_[:2, 4:n_ch]])\n",
    "            output[:, :, :, :, applied_sigmoid_idx] = torch.sigmoid(output[:, :, :, :, applied_sigmoid_idx])\n",
    "\n",
    "            pred = output[..., :4].clone()\n",
    "            pred[..., 0] += self.grid_x[output_id]\n",
    "            pred[..., 1] += self.grid_y[output_id]\n",
    "            pred[..., 2] = torch.exp(pred[..., 2]) * self.anchor_w[output_id]\n",
    "            pred[..., 3] = torch.exp(pred[..., 3]) * self.anchor_h[output_id]\n",
    "\n",
    "            obj_mask, tgt_mask, tgt_scale, target = self.build_target(pred, labels, batchsize, fsize, n_ch, output_id)\n",
    "\n",
    "            # loss calculation\n",
    "            output[..., 4] *= obj_mask\n",
    "#             output[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            tgt_mask_idx = torch.cat([torch.arange(4), torch.arange(5, n_ch)])\n",
    "            output[:, :, :, :, tgt_mask_idx] *= tgt_mask\n",
    "            output[..., 2:4] *= tgt_scale\n",
    "\n",
    "            target[..., 4] *= obj_mask\n",
    "#             target[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            target[:, :, :, :, tgt_mask_idx] *= tgt_mask\n",
    "            target[..., 2:4] *= tgt_scale\n",
    "            F.mse_loss(input=output[..., 2:4], target=target[..., 2:4], reduction='sum')\n",
    "            loss_wh += F.mse_loss(input=output[..., 2:4], target=target[..., 2:4], reduction='sum') / 2\n",
    "            loss_xy += F.binary_cross_entropy(input=output[..., :2], target=target[..., :2],\n",
    "                                              weight=tgt_scale * tgt_scale, reduction='sum')\n",
    "            \n",
    "            loss_obj += F.binary_cross_entropy(input=output[..., 4], target=target[..., 4], reduction='sum')\n",
    "            loss_cls += F.binary_cross_entropy(input=output[..., 5:], target=target[..., 5:], reduction='sum')\n",
    "            loss_l2 += F.mse_loss(input=output, target=target, reduction='sum')\n",
    "        loss = loss_xy + loss_wh + loss_obj + loss_cls\n",
    "\n",
    "        return loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2\n",
    "device = \"cuda\"\n",
    "criterion = Yolo_loss(device=device, batch=1, n_classes=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "bboxes_pred = model(torch.zeros(1, 3, 608, 608).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "loss = criterion(bboxes_pred, torch.zeros(10, 10, 5).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_module = torch.jit.script(criterion)\n",
    "torch.jit.save(scripted_module, \"scripted_yolo_v4_loss.pt\")\n",
    "load_scripted_loss = torch.jit.load(\"scripted_yolo_v4_loss.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_pred = model(torch.zeros(1, 3, 608, 608).to(device))\n",
    "scripted_loss = load_scripted_loss(bboxes_pred, torch.zeros(10, 10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerically check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(scripted_loss, loss):\n",
    "  np.testing.assert_almost_equal(i.to(\"cpu\").detach().numpy(), j.to(\"cpu\").detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_scripted_loss.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f064fc219a36dd5d1a722beaf51e284bcdd0f712e21897aaedb76bc4497938f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gnn': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
